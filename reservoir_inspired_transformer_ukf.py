#!/usr/bin/env python3
# qr_scaling_transformer_ukf.py
"""
Q/Rç¼©æ”¾å› å­è°ƒæ•´ç‰ˆï¼šæ™ºèƒ½UKFè°ƒåŸºç¡€Q/R + Transformerè°ƒç¼©æ”¾å› å­ + Reservoir + ç½®ä¿¡åº¦
æ¶æ„ï¼šæ™ºèƒ½UKF(30æ­¥è°ƒæ•´åŸºç¡€Q/R) + Transformer(å®æ—¶é¢„æµ‹ç¼©æ”¾å› å­) + ç½®ä¿¡åº¦èåˆ
"""

import argparse
import copy
import os
import math
from datetime import datetime
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from sklearn.preprocessing import StandardScaler
from filterpy.kalman import UnscentedKalmanFilter as UKF
from filterpy.kalman import MerweScaledSigmaPoints
from collections import deque
import warnings

warnings.filterwarnings("ignore", category=UserWarning)

# ç›´æ¥ä»ä½ çš„fixed_dynamic_ukf.pyå¼•å…¥
try:
    from fixed_dynamic_ukf import EnhancedIndependentDynamicUKF, infer_vehicle_type_from_path
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥fixed_dynamic_ukfï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
    def infer_vehicle_type_from_path(path):
        return "medium_large_quad"


# =========================
# Reservoirè®°å¿†æ¨¡å—ï¼ˆä¿æŒä¸å˜ï¼‰
# =========================

class LightweightReservoir(nn.Module):
    """è½»é‡çº§å‚¨å±‚è®¡ç®—"""

    def __init__(self, input_size, reservoir_size=32, spectral_radius=0.8, input_scaling=0.3, leak_rate=0.5):
        super(LightweightReservoir, self).__init__()

        self.input_size = input_size
        self.reservoir_size = reservoir_size
        self.leak_rate = leak_rate

        W_in = torch.randn(reservoir_size, input_size) * input_scaling
        self.register_buffer('W_in', W_in)

        W_res = torch.randn(reservoir_size, reservoir_size) * 0.1
        eigenvals = torch.linalg.eigvals(W_res)
        spectral_rad = torch.max(torch.abs(eigenvals)).real
        if spectral_rad > 1e-6:
            W_res = W_res * (spectral_radius / spectral_rad)
        self.register_buffer('W_res', W_res)

    def forward(self, input_seq):
        batch_size, seq_len, input_size = input_seq.shape

        states = []
        current_state = torch.zeros(batch_size, self.reservoir_size, device=input_seq.device)

        for t in range(seq_len):
            input_contrib = torch.tanh(torch.mm(input_seq[:, t, :], self.W_in.t()))
            reservoir_contrib = torch.mm(current_state, self.W_res.t())

            new_state = (1 - self.leak_rate) * current_state + self.leak_rate * torch.tanh(
                input_contrib + reservoir_contrib)
            current_state = new_state
            states.append(current_state.unsqueeze(1))

        reservoir_states = torch.cat(states, dim=1)
        return reservoir_states


# =========================
# Q/Rç¼©æ”¾å› å­Transformerï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼‰
# =========================

class QRScalingTransformerNN(nn.Module):
    """é¢„æµ‹Q/Rç¼©æ”¾å› å­çš„Transformer + Reservoir + ç½®ä¿¡åº¦"""

    def __init__(self, input_dim, d_model=128, nlayers=2, nhead=4, dropout=0.1, reservoir_size=32):
        super().__init__()

        self.d_model = d_model
        self.input_dim = input_dim

        # è¾“å…¥å¤„ç†
        self.input_projection = nn.Sequential(
            nn.Linear(input_dim, d_model),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.LayerNorm(d_model)
        )

        # Transformerç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 2,
            dropout=dropout,
            activation='gelu',
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=nlayers)

        # Reservoirè®°å¿†æ¨¡å—
        self.reservoir = LightweightReservoir(
            input_size=d_model,
            reservoir_size=reservoir_size,
            spectral_radius=0.8,
            input_scaling=0.3,
            leak_rate=0.5
        )

        # ç‰¹å¾èåˆ
        self.feature_fusion = nn.Sequential(
            nn.Linear(d_model + reservoir_size, d_model),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.LayerNorm(d_model)
        )

        self.norm = nn.LayerNorm(d_model)

        # å¤šä»»åŠ¡è¾“å‡ºå¤´
        # ä¸»ä»»åŠ¡ï¼šQ/Rç¼©æ”¾å› å­é¢„æµ‹
        self.qr_scale_head = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, 2)  # q_scale, r_scale
        )

        # è¾…åŠ©ä»»åŠ¡ï¼šç½®ä¿¡åº¦é¢„æµ‹
        self.confidence_head = nn.Sequential(
            nn.Linear(d_model, d_model // 4),
            nn.GELU(),
            nn.Linear(d_model // 4, 1),
            nn.Sigmoid()
        )

        # è¾…åŠ©ä»»åŠ¡ï¼šè½½å…·ç±»å‹é¢„æµ‹
        self.vehicle_head = nn.Sequential(
            nn.Linear(d_model, d_model // 4),
            nn.GELU(),
            nn.Linear(d_model // 4, 4)  # 4ç§è½½å…·ç±»å‹
        )

        # Q/Rç¼©æ”¾å› å­èŒƒå›´ï¼ˆæ›´åˆç†çš„èŒƒå›´ï¼‰
        self.qr_ranges = {
            'q_scale': (0.1, 3.0),  # QçŸ©é˜µç¼©æ”¾ï¼š0.1å€åˆ°3å€
            'r_scale': (0.5, 2.0),  # RçŸ©é˜µç¼©æ”¾ï¼š0.5å€åˆ°2å€
        }

    def forward(self, x):
        batch_size = x.size(0)

        # æ‰©å±•ä¸ºåºåˆ—
        if x.dim() == 2:
            x = x.unsqueeze(1)

        # Transformerç‰¹å¾æå–
        x_proj = self.input_projection(x)
        transformer_features = self.transformer(x_proj)

        # Reservoirè®°å¿†è®¡ç®—
        reservoir_states = self.reservoir(transformer_features)

        # ç‰¹å¾èåˆ
        fused_features = torch.cat([transformer_features, reservoir_states], dim=-1)
        fused_features = self.feature_fusion(fused_features)

        # å…¨å±€ç‰¹å¾
        global_features = fused_features.squeeze(1)
        h = self.norm(global_features)

        # å¤šä»»åŠ¡è¾“å‡º
        # 1. Q/Rç¼©æ”¾å› å­é¢„æµ‹ï¼ˆä¸»ä»»åŠ¡ï¼‰
        raw_qr = self.qr_scale_head(h)

        q_scale = torch.sigmoid(raw_qr[:, 0]) * (
                self.qr_ranges['q_scale'][1] - self.qr_ranges['q_scale'][0]
        ) + self.qr_ranges['q_scale'][0]

        r_scale = torch.sigmoid(raw_qr[:, 1]) * (
                self.qr_ranges['r_scale'][1] - self.qr_ranges['r_scale'][0]
        ) + self.qr_ranges['r_scale'][0]

        qr_scales = torch.stack([q_scale, r_scale], dim=1)

        # 2. ç½®ä¿¡åº¦é¢„æµ‹
        confidence = self.confidence_head(h).squeeze(-1)

        # 3. è½½å…·ç±»å‹é¢„æµ‹ï¼ˆè¾…åŠ©æ™ºèƒ½UKFï¼‰
        vehicle_logits = self.vehicle_head(h)
        vehicle_probs = F.softmax(vehicle_logits, dim=1)

        return qr_scales, confidence, vehicle_probs, vehicle_logits


# =========================
# æ™ºèƒ½Q/Rè°ƒèŠ‚UKFï¼ˆä»final_working_baseline_methods.pyç§»æ¤ï¼‰
# =========================

class SmartQREnhancedUKF:
    """æ™ºèƒ½UKFï¼šè‡ªåŠ¨è°ƒèŠ‚Q/RçŸ©é˜µ"""

    def __init__(self, dt=0.1):
        self.dt = dt
        self.ukf = None
        self.initialized = False

        # æ™ºèƒ½Q/Rè°ƒèŠ‚å‚æ•°
        self.motion_history = []
        self.current_motion_type = "steady"
        self.qr_adaptation_enabled = True

        # ç»Ÿè®¡ä¿¡æ¯
        self.recovery_count = 0
        self.total_steps = 0
        self.qr_adjustment_count = 0

        # å†å²çŠ¶æ€ç”¨äºæ¢å¤
        self.last_velocity = None
        self.position_history = []

        # Q/Rç¼©æ”¾ç›¸å…³
        self.current_q_scale = 1.0
        self.current_r_scale = 1.0
        self.base_Q = None
        self.base_R = None

    def _fx(self, x: np.ndarray, dt=None) -> np.ndarray:
        """çŠ¶æ€è½¬ç§»å‡½æ•°ï¼šåŒ€é€Ÿè¿åŠ¨æ¨¡å‹"""
        dt = self.dt if dt is None else dt
        nx = x.copy()
        nx[0] += nx[3] * dt  # x += vx * dt
        nx[1] += nx[4] * dt  # y += vy * dt
        nx[2] += nx[5] * dt  # z += vz * dt
        return nx

    def _hx(self, x: np.ndarray) -> np.ndarray:
        """è§‚æµ‹å‡½æ•°ï¼šåªè§‚æµ‹ä½ç½®"""
        return x[:3]

    def _regularize_covariance_matrix(self, P, min_eigenvalue=1e-8):
        """æ­£åˆ™åŒ–åæ–¹å·®çŸ©é˜µç¡®ä¿æ­£å®šæ€§"""
        try:
            P_sym = 0.5 * (P + P.T)
            eigenvals, eigenvecs = np.linalg.eigh(P_sym)
            eigenvals = np.maximum(eigenvals, min_eigenvalue)
            P_fixed = eigenvecs @ np.diag(eigenvals) @ eigenvecs.T
            return P_fixed
        except Exception:
            return np.eye(P.shape[0]) * min_eigenvalue

    def _analyze_motion_pattern(self):
        """åˆ†æè¿åŠ¨æ¨¡å¼å¹¶è°ƒæ•´Q/RçŸ©é˜µ"""
        if len(self.motion_history) < 10:
            return

        recent_positions = np.array(self.motion_history[-10:])
        velocities = np.diff(recent_positions, axis=0) / self.dt
        accelerations = np.diff(velocities, axis=0) / self.dt if len(velocities) > 1 else np.zeros((1, 3))

        # è®¡ç®—è¿åŠ¨ç‰¹å¾
        avg_speed = np.mean(np.linalg.norm(velocities, axis=1))
        speed_variance = np.var(np.linalg.norm(velocities, axis=1))
        avg_acceleration = np.mean(np.linalg.norm(accelerations, axis=1)) if len(accelerations) > 0 else 0

        # æ ¹æ®è¿åŠ¨ç‰¹å¾åˆ¤æ–­å’Œè°ƒæ•´
        if speed_variance > 5.0 and avg_acceleration > 3.0:
            motion_type = "aggressive"
            q_scale = 2.5
            r_scale = 1.5
        elif avg_speed > 15.0:
            motion_type = "fast_cruise"
            q_scale = 1.2
            r_scale = 0.8
        elif speed_variance > 2.0:
            motion_type = "maneuvering"
            q_scale = 1.5
            r_scale = 1.0
        elif avg_speed < 1.0:
            motion_type = "hovering"
            q_scale = 0.3
            r_scale = 0.6
        else:
            motion_type = "steady"
            q_scale = 1.0
            r_scale = 1.0

        # åªåœ¨æ¨¡å¼æ”¹å˜æ—¶æ›´æ–°åŸºç¡€Q/R
        if motion_type != self.current_motion_type and self.qr_adaptation_enabled:
            self.current_motion_type = motion_type
            self.qr_adjustment_count += 1

            # æ›´æ–°åŸºç¡€Q/RçŸ©é˜µ
            self.base_Q = np.diag([0.1, 0.1, 0.1, 0.5, 0.5, 0.5]) * q_scale
            self.base_R = np.diag([0.5, 0.5, 0.5]) * r_scale

            # åº”ç”¨å½“å‰ç¼©æ”¾å› å­
            self.ukf.Q = self.base_Q * self.current_q_scale
            self.ukf.R = self.base_R * self.current_r_scale

    def initialize(self, initial_state: np.ndarray) -> bool:
        """åˆå§‹åŒ–UKF"""
        try:
            # åˆ›å»ºsigmaç‚¹ç”Ÿæˆå™¨
            points = MerweScaledSigmaPoints(n=6, alpha=0.1, beta=2.0, kappa=0.0)

            # åˆ›å»ºUKFå®ä¾‹
            self.ukf = UKF(dim_x=6, dim_z=3, dt=self.dt, hx=self._hx, fx=self._fx, points=points)

            # è®¾ç½®åˆå§‹Q/RçŸ©é˜µ
            self.base_Q = np.diag([0.1, 0.1, 0.1, 0.5, 0.5, 0.5])
            self.base_R = np.diag([0.5, 0.5, 0.5])
            self.ukf.Q = self.base_Q.copy()
            self.ukf.R = self.base_R.copy()

            # è®¾ç½®åˆå§‹çŠ¶æ€
            if len(initial_state) >= 6:
                self.ukf.x = initial_state[:6].copy().astype(float)
            elif len(initial_state) >= 3:
                self.ukf.x = np.array([
                    initial_state[0], initial_state[1], initial_state[2],
                    0.0, 0.0, 0.0
                ], dtype=float)
            else:
                return False

            # è®¾ç½®åˆå§‹åæ–¹å·®çŸ©é˜µ
            self.ukf.P = np.eye(6) * 10.0
            self.ukf.P[0:3, 0:3] *= 5.0  # ä½ç½®ä¸ç¡®å®šæ€§
            self.ukf.P[3:6, 3:6] *= 2.0  # é€Ÿåº¦ä¸ç¡®å®šæ€§

            # ç¡®ä¿åæ–¹å·®çŸ©é˜µæ­£å®š
            self.ukf.P = self._regularize_covariance_matrix(self.ukf.P)

            # é‡ç½®ç»Ÿè®¡
            self.recovery_count = 0
            self.total_steps = 0
            self.qr_adjustment_count = 0
            self.position_history = [initial_state[:3].copy()]
            self.motion_history = [initial_state[:3].copy()]
            self.current_motion_type = "steady"
            self.current_q_scale = 1.0
            self.current_r_scale = 1.0

            self.initialized = True
            return True

        except Exception as e:
            print(f"SmartQREnhancedUKFåˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def apply_qr_scaling(self, q_scale, r_scale):
        """åº”ç”¨Q/Rç¼©æ”¾å› å­åˆ°å½“å‰åŸºç¡€çŸ©é˜µ"""
        if not self.initialized or self.ukf is None or self.base_Q is None or self.base_R is None:
            return False

        try:
            self.current_q_scale = q_scale
            self.current_r_scale = r_scale

            # åº”ç”¨ç¼©æ”¾ï¼šæœ€ç»ˆQ/R = åŸºç¡€Q/R Ã— ç¼©æ”¾å› å­
            self.ukf.Q = self.base_Q * q_scale
            self.ukf.R = self.base_R * r_scale

            return True

        except Exception as e:
            return False

    def step(self, z_xyz: np.ndarray) -> np.ndarray:
        """æ™ºèƒ½UKFæ­¥éª¤ï¼šè‡ªåŠ¨è°ƒèŠ‚Q/R + åº”ç”¨ç¼©æ”¾"""
        self.total_steps += 1
        measurement = np.array(z_xyz[:3], dtype=float)

        if not self.initialized or self.ukf is None:
            return measurement

        try:
            # æ›´æ–°è¿åŠ¨å†å²
            self.motion_history.append(measurement.copy())
            if len(self.motion_history) > 50:  # ä¿æŒæœ€è¿‘50ä¸ªä½ç½®
                self.motion_history.pop(0)

            # æ™ºèƒ½Q/Rè°ƒæ•´ï¼ˆæ¯10æ­¥è¿›è¡Œä¸€æ¬¡ï¼‰
            if self.total_steps % 10 == 0:
                self._analyze_motion_pattern()

            # é¢„æµ‹æ­¥éª¤
            self.ukf.predict()

            # ç¡®ä¿åæ–¹å·®çŸ©é˜µæ­£å®š
            self.ukf.P = self._regularize_covariance_matrix(self.ukf.P)

            # æ›´æ–°æ­¥éª¤
            self.ukf.update(measurement)

            # æ›´æ–°åå†æ¬¡æ£€æŸ¥
            self.ukf.P = self._regularize_covariance_matrix(self.ukf.P)

            # æ›´æ–°å†å²ä¿¡æ¯
            self.position_history.append(measurement.copy())
            if len(self.position_history) > 10:
                self.position_history.pop(0)

            return self.ukf.x[:3].copy()

        except Exception as e:
            self.recovery_count += 1
            # æ¢å¤ç­–ç•¥
            try:
                # é‡ç½®åæ–¹å·®çŸ©é˜µ
                self.ukf.P = np.eye(6) * 10.0
                self.ukf.P[0:3, 0:3] *= 5.0
                self.ukf.P[3:6, 3:6] *= 2.0

                # æ¢å¤åˆ°å®‰å…¨çŠ¶æ€
                if len(self.position_history) > 0:
                    self.ukf.x[:3] = self.position_history[-1]
                else:
                    self.ukf.x[:3] = measurement

                return self.ukf.x[:3].copy()

            except Exception as e2:
                return measurement

    def get_current_mode(self):
        """è·å–å½“å‰é£è¡Œæ¨¡å¼"""
        return self.current_motion_type

    def get_qr_info(self):
        """è·å–Q/Rä¿¡æ¯"""
        return {
            'q_scale': self.current_q_scale,
            'r_scale': self.current_r_scale,
            'base_Q_trace': np.trace(self.base_Q) if self.base_Q is not None else 0,
            'base_R_trace': np.trace(self.base_R) if self.base_R is not None else 0,
            'final_Q_trace': np.trace(self.ukf.Q),
            'final_R_trace': np.trace(self.ukf.R),
            'motion_type': self.current_motion_type
        }


# =========================
# æ™ºèƒ½UKFåŒ…è£…å™¨ï¼ˆæ›¿æ¢åŸæ¥çš„SmartUKFWithQRScalingï¼‰
# =========================

class SmartUKFWithQRScaling:
    """æ™ºèƒ½UKF + Q/Rç¼©æ”¾å› å­åº”ç”¨"""

    def __init__(self, dt=0.1, vehicle_type="medium_large_quad"):
        self.dt = dt
        self.vehicle_type = vehicle_type
        self.smart_ukf = SmartQREnhancedUKF(dt=dt)
        self.step_count = 0
        self.qr_update_interval = 30  # 30æ­¥æ›´æ–°ä¸€æ¬¡æ™ºèƒ½UKFçš„åŸºç¡€Q/R

        # å½“å‰ç¼©æ”¾å› å­
        self.current_q_scale = 1.0
        self.current_r_scale = 1.0

    def initialize(self, initial_state):
        """åˆå§‹åŒ–åŒ…è£…çš„æ™ºèƒ½UKF"""
        return self.smart_ukf.initialize(initial_state)

    def apply_qr_scaling(self, q_scale, r_scale):
        """åº”ç”¨Q/Rç¼©æ”¾å› å­åˆ°åŸºç¡€çŸ©é˜µ"""
        self.current_q_scale = q_scale
        self.current_r_scale = r_scale
        return self.smart_ukf.apply_qr_scaling(q_scale, r_scale)

    def step(self, measurement):
        """UKFæ­¥éª¤ï¼šæ¯30æ­¥æ›´æ–°åŸºç¡€Q/Rï¼Œæ¯æ­¥åº”ç”¨ç¼©æ”¾"""
        self.step_count += 1

        # æ¯30æ­¥è®©æ™ºèƒ½UKFæ›´æ–°åŸºç¡€Q/RçŸ©é˜µ
        if self.step_count % self.qr_update_interval == 0:
            # æ™ºèƒ½UKFè¿›è¡Œè½½å…·ç±»å‹å’Œé£è¡Œæ¨¡å¼åˆ¤æ–­ï¼Œæ›´æ–°åŸºç¡€Q/R
            result = self.smart_ukf.step(measurement)
            # é‡æ–°åº”ç”¨å½“å‰ç¼©æ”¾å› å­
            self.smart_ukf.apply_qr_scaling(self.current_q_scale, self.current_r_scale)
            return result
        else:
            # æ™®é€šæ­¥éª¤ï¼šåªè¿è¡ŒUKFï¼ŒQ/Rä¿æŒå½“å‰ç¼©æ”¾çŠ¶æ€
            return self.smart_ukf.step(measurement)

    def get_current_mode(self):
        """è·å–å½“å‰é£è¡Œæ¨¡å¼"""
        return self.smart_ukf.get_current_mode()

    def get_qr_info(self):
        """è·å–Q/Rä¿¡æ¯"""
        return self.smart_ukf.get_qr_info()


# =========================
# ç½®ä¿¡åº¦é©±åŠ¨çš„Q/Rç¼©æ”¾é¢„æµ‹å™¨ï¼ˆä¿æŒä¸å˜ï¼‰
# =========================

class QRScalingAdaptivePredictor:
    """åŸºäºç½®ä¿¡åº¦çš„Q/Rç¼©æ”¾è‡ªé€‚åº”é¢„æµ‹å™¨"""

    def __init__(self, dt=0.1, vehicle_type="medium_large_quad", max_prediction_steps=3):
        self.dt = dt
        self.vehicle_type = vehicle_type
        self.max_prediction_steps = max_prediction_steps

        # ç½®ä¿¡åº¦é˜ˆå€¼
        self.high_confidence_threshold = 0.7  # è°ƒæ•´ä¸ºæ›´åˆç†çš„é˜ˆå€¼
        self.low_confidence_threshold = 0.3

        # ç»Ÿè®¡ä¿¡æ¯
        self.nn_qr_usage_count = 0
        self.hybrid_qr_usage_count = 0
        self.default_qr_usage_count = 0

    def safe_predict(self, nn_outputs, current_pos, target_pos, verbose=False):
        """ç½®ä¿¡åº¦é©±åŠ¨çš„Q/Rç¼©æ”¾è‡ªé€‚åº”é¢„æµ‹"""
        try:
            qr_scales, confidence, vehicle_probs, vehicle_logits = nn_outputs

            if torch.any(torch.isnan(qr_scales)) or torch.any(torch.isnan(confidence)):
                return None, float('inf')

            # åˆ›å»ºæ™ºèƒ½UKFåŒ…è£…å™¨
            smart_ukf_wrapper = SmartUKFWithQRScaling(dt=self.dt, vehicle_type=self.vehicle_type)

            # åˆå§‹åŒ–
            initial_vel = np.random.normal(0, 0.02, 3)
            initial_state = np.concatenate([current_pos, initial_vel])

            if not smart_ukf_wrapper.initialize(initial_state):
                return None, float('inf')

            confidence_val = float(confidence)

            if verbose:
                print(f"    Q/Rç¼©æ”¾è‡ªé€‚åº”é¢„æµ‹:")
                print(f"      ç½®ä¿¡åº¦: {confidence_val:.4f}")
                predicted_vehicle = torch.argmax(vehicle_probs).item()
                vehicle_names = ["micro_quad", "medium_large_quad", "fixed_wing", "heavy_multirotor"]
                print(f"      é¢„æµ‹è½½å…·: {vehicle_names[predicted_vehicle]}")

            # è‡ªé€‚åº”Q/Rç¼©æ”¾ç­–ç•¥
            if confidence_val > self.high_confidence_threshold:
                # é«˜ç½®ä¿¡åº¦ï¼šä½¿ç”¨NNçš„Q/Rç¼©æ”¾å› å­
                return self._high_confidence_qr_prediction(smart_ukf_wrapper, qr_scales, current_pos, target_pos,
                                                           verbose)

            elif confidence_val < self.low_confidence_threshold:
                # ä½ç½®ä¿¡åº¦ï¼šä½¿ç”¨é»˜è®¤ç¼©æ”¾(1.0, 1.0)
                return self._low_confidence_qr_prediction(smart_ukf_wrapper, current_pos, target_pos, verbose)

            else:
                # ä¸­ç­‰ç½®ä¿¡åº¦ï¼šæ··åˆç¼©æ”¾ç­–ç•¥
                return self._hybrid_qr_prediction(smart_ukf_wrapper, qr_scales, confidence_val, current_pos, target_pos,
                                                  verbose)

        except Exception as e:
            if verbose:
                print(f"    æ•´ä½“Q/Rç¼©æ”¾é¢„æµ‹å¤±è´¥: {e}")
            return None, float('inf')

    def _high_confidence_qr_prediction(self, smart_ukf_wrapper, qr_scales, current_pos, target_pos, verbose=False):
        """é«˜ç½®ä¿¡åº¦ï¼šä½¿ç”¨NNçš„Q/Rç¼©æ”¾å› å­"""
        try:
            self.nn_qr_usage_count += 1

            # æå–Q/Rç¼©æ”¾å› å­
            scales_np = qr_scales.detach().cpu().numpy()
            if scales_np.ndim > 1:
                scales_np = scales_np.flatten()

            q_scale, r_scale = float(scales_np[0]), float(scales_np[1])

            if verbose:
                print(f"      é«˜ç½®ä¿¡åº¦æ¨¡å¼ï¼šä½¿ç”¨NN Q/Rç¼©æ”¾")
                print(f"      ç¼©æ”¾å› å­: Q={q_scale:.3f}, R={r_scale:.3f}")

            # æ¸è¿›å¼å¤šæ­¥é¢„æµ‹
            current_pred = current_pos.copy()

            for step in range(self.max_prediction_steps):
                progress = (step + 1) / self.max_prediction_steps
                intermediate_target = current_pos + progress * (target_pos - current_pos)
                noise = np.random.normal(0, 0.25, 3)
                noisy_obs = intermediate_target + noise

                # åœ¨æ¯æ­¥åº”ç”¨NNé¢„æµ‹çš„Q/Rç¼©æ”¾
                smart_ukf_wrapper.apply_qr_scaling(q_scale, r_scale)

                # æ‰§è¡Œæ™ºèƒ½UKFæ­¥éª¤ï¼ˆæ¯30æ­¥ä¼šè‡ªåŠ¨æ›´æ–°åŸºç¡€Q/Rï¼‰
                pred_state = smart_ukf_wrapper.step(noisy_obs)
                current_pred = pred_state[:3]

                if np.any(np.isnan(current_pred)) or np.any(np.isinf(current_pred)):
                    break

            final_error = np.linalg.norm(current_pred - target_pos)

            if verbose:
                print(f"      å½“å‰é£è¡Œæ¨¡å¼: {smart_ukf_wrapper.get_current_mode()}")
                qr_info = smart_ukf_wrapper.get_qr_info()
                print(f"      æœ€ç»ˆQ trace: {qr_info['final_Q_trace']:.3f}, R trace: {qr_info['final_R_trace']:.3f}")
                print(f"      æœ€ç»ˆé¢„æµ‹: [{current_pred[0]:.6f}, {current_pred[1]:.6f}, {current_pred[2]:.6f}]")

            return current_pred, final_error

        except Exception as e:
            if verbose:
                print(f"      é«˜ç½®ä¿¡åº¦Q/Rç¼©æ”¾é¢„æµ‹å¤±è´¥: {e}")
            return self._low_confidence_qr_prediction(smart_ukf_wrapper, current_pos, target_pos, verbose)

    def _low_confidence_qr_prediction(self, smart_ukf_wrapper, current_pos, target_pos, verbose=False):
        """ä½ç½®ä¿¡åº¦ï¼šä½¿ç”¨é»˜è®¤Q/Rç¼©æ”¾(1.0, 1.0)"""
        try:
            self.default_qr_usage_count += 1

            if verbose:
                print(f"      ä½ç½®ä¿¡åº¦æ¨¡å¼ï¼šé»˜è®¤Q/Rç¼©æ”¾(1.0, 1.0)")

            # ä½¿ç”¨é»˜è®¤ç¼©æ”¾å› å­
            current_pred = current_pos.copy()

            for step in range(self.max_prediction_steps):
                progress = (step + 1) / self.max_prediction_steps
                intermediate_target = current_pos + progress * (target_pos - current_pos)
                noise = np.random.normal(0, 0.25, 3)
                noisy_obs = intermediate_target + noise

                # åº”ç”¨é»˜è®¤ç¼©æ”¾
                smart_ukf_wrapper.apply_qr_scaling(1.0, 1.0)

                pred_state = smart_ukf_wrapper.step(noisy_obs)
                current_pred = pred_state[:3]

                if np.any(np.isnan(current_pred)) or np.any(np.isinf(current_pred)):
                    break

            final_error = np.linalg.norm(current_pred - target_pos)
            return current_pred, final_error

        except Exception as e:
            if verbose:
                print(f"      ä½ç½®ä¿¡åº¦Q/Rç¼©æ”¾é¢„æµ‹å¤±è´¥: {e}")
            return None, float('inf')

    def _hybrid_qr_prediction(self, smart_ukf_wrapper, qr_scales, confidence_val, current_pos, target_pos,
                              verbose=False):
        """ä¸­ç­‰ç½®ä¿¡åº¦ï¼šæ··åˆQ/Rç¼©æ”¾ç­–ç•¥"""
        try:
            self.hybrid_qr_usage_count += 1

            # æå–NNé¢„æµ‹çš„ç¼©æ”¾å› å­
            scales_np = qr_scales.detach().cpu().numpy()
            if scales_np.ndim > 1:
                scales_np = scales_np.flatten()

            q_scale_nn, r_scale_nn = float(scales_np[0]), float(scales_np[1])

            # é»˜è®¤ç¼©æ”¾å› å­
            q_scale_default, r_scale_default = 1.0, 1.0

            # ç½®ä¿¡åº¦åŠ æƒèåˆ
            weight = confidence_val
            q_scale_fused = weight * q_scale_nn + (1 - weight) * q_scale_default
            r_scale_fused = weight * r_scale_nn + (1 - weight) * r_scale_default

            if verbose:
                print(f"      æ··åˆQ/Rç¼©æ”¾æ¨¡å¼ï¼šæƒé‡={weight:.3f}")
                print(f"      èåˆç¼©æ”¾: Q={q_scale_fused:.3f}, R={r_scale_fused:.3f}")

            # é¢„æµ‹è¿‡ç¨‹
            current_pred = current_pos.copy()

            for step in range(self.max_prediction_steps):
                progress = (step + 1) / self.max_prediction_steps
                intermediate_target = current_pos + progress * (target_pos - current_pos)
                noise = np.random.normal(0, 0.25, 3)
                noisy_obs = intermediate_target + noise

                # åº”ç”¨èåˆçš„ç¼©æ”¾å› å­
                smart_ukf_wrapper.apply_qr_scaling(q_scale_fused, r_scale_fused)

                pred_state = smart_ukf_wrapper.step(noisy_obs)
                current_pred = pred_state[:3]

                if np.any(np.isnan(current_pred)) or np.any(np.isinf(current_pred)):
                    break

            final_error = np.linalg.norm(current_pred - target_pos)
            return current_pred, final_error

        except Exception as e:
            if verbose:
                print(f"      æ··åˆQ/Rç¼©æ”¾é¢„æµ‹å¤±è´¥: {e}")
            return self._low_confidence_qr_prediction(smart_ukf_wrapper, current_pos, target_pos, verbose)

    def get_usage_stats(self):
        """è·å–Q/Rç¼©æ”¾ä½¿ç”¨ç»Ÿè®¡"""
        total = self.nn_qr_usage_count + self.hybrid_qr_usage_count + self.default_qr_usage_count
        if total == 0:
            return {'nn_qr_scaling': 0, 'hybrid_qr_scaling': 0, 'default_qr_scaling': 0}

        return {
            'nn_qr_scaling': self.nn_qr_usage_count / total * 100,
            'hybrid_qr_scaling': self.hybrid_qr_usage_count / total * 100,
            'default_qr_scaling': self.default_qr_usage_count / total * 100,
            'total_predictions': total
        }


# =========================
# è®­ç»ƒå™¨ï¼ˆå…³é”®ä¿®æ”¹ï¼šå»æ‰æœ€å¤§å¸§æ•°é™åˆ¶ï¼‰
# =========================

class QRScalingHybridTrainer:
    """Q/Rç¼©æ”¾ç‰ˆè®­ç»ƒå™¨"""

    def __init__(self, data_input, device='cpu'):
        self.data_input = data_input
        self.device = torch.device(device)

        print(f"Q/Rç¼©æ”¾ç‰ˆæ•°æ®åŠ è½½ä¸­... (æ— æœ€å¤§ç‚¹æ•°é™åˆ¶)")
        print(f"æ¶æ„: æ™ºèƒ½UKF(30æ­¥è°ƒåŸºç¡€Q/R) + Transformer(å®æ—¶Q/Rç¼©æ”¾) + Reservoir + ç½®ä¿¡åº¦")

        self.load_and_prepare_data()

    def load_and_prepare_data(self):
        """å…³é”®ä¿®æ”¹ï¼šå»æ‰æœ€å¤§å¸§æ•°é™åˆ¶"""
        all_trajectories = []

        if isinstance(self.data_input, str):
            files = [f.strip() for f in self.data_input.split(',') if f.strip()]
        else:
            files = [self.data_input]

        for file_path in files:
            if not os.path.exists(file_path):
                print(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                continue

            print(f"  åŠ è½½: {file_path}")
            try:
                df = pd.read_csv(file_path)

                time_cols = [col for col in df.columns if 'time' in col.lower()]
                if not time_cols:
                    print(f"    è­¦å‘Š: {file_path} ä¸­æœªæ‰¾åˆ°æ—¶é—´åˆ—")
                    continue

                pos_cols = []
                for prefix in ['x', 'y', 'z']:
                    for col in df.columns:
                        if col.lower() == prefix or col.lower() == f'{prefix}_true' or col.lower() == f'true_{prefix}':
                            pos_cols.append(col)
                            break

                if len(pos_cols) < 3:
                    print(f"    è­¦å‘Š: {file_path} ä¸­ä½ç½®åˆ—ä¸å®Œæ•´ {pos_cols}")
                    continue

                # å…³é”®ä¿®æ”¹ï¼šä¸å†é™åˆ¶æœ€å¤§ç‚¹æ•°ï¼Œä½¿ç”¨æ‰€æœ‰æ•°æ®
                positions = df[pos_cols].values[:, :3]

                if len(positions) < 50:
                    print(f"    è·³è¿‡: æ•°æ®ç‚¹å¤ªå°‘")
                    continue

                if np.any(np.isnan(positions)):
                    positions = positions[~np.any(np.isnan(positions), axis=1)]

                time_data = df[time_cols[0]].values[:len(positions)]
                if len(time_data) > 1:
                    dt_values = np.diff(time_data)
                    dt = np.median(dt_values)
                else:
                    dt = 0.1

                # æ¨æ–­è½½å…·ç±»å‹
                vehicle_type = infer_vehicle_type_from_path(file_path)

                split_point = int(len(positions) * 0.8)
                train_positions = positions[:split_point]
                test_positions = positions[split_point:]

                all_trajectories.append({
                    'train_positions': train_positions,
                    'test_positions': test_positions,
                    'dt': dt,
                    'vehicle_type': vehicle_type,
                    'source_file': file_path
                })

                print(f"    æˆåŠŸ: è½½å…·={vehicle_type}, è®­ç»ƒ={len(train_positions)}, æµ‹è¯•={len(test_positions)}")

            except Exception as e:
                print(f"    é”™è¯¯: {e}")
                continue

        if not all_trajectories:
            raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®æ–‡ä»¶")

        print(f"\næ€»è®¡åŠ è½½ {len(all_trajectories)} ä¸ªè½¨è¿¹")

        all_dts = [traj['dt'] for traj in all_trajectories]
        self.median_dt = np.median(all_dts)
        print(f"ä¸­ä½æ—¶é—´é—´éš”: {self.median_dt:.3f}s")

        self.train_data = []
        self.test_data = []

        for traj in all_trajectories:
            train_samples = self._generate_training_data(traj['train_positions'], traj['dt'], traj['vehicle_type'])
            self.train_data.extend(train_samples)

            test_samples = self._generate_training_data(traj['test_positions'], traj['dt'], traj['vehicle_type'])
            self.test_data.extend(test_samples)

        print(f"è®­ç»ƒæ ·æœ¬: {len(self.train_data)}")
        print(f"æµ‹è¯•æ ·æœ¬: {len(self.test_data)}")

        all_train_features = np.array([sample['features'] for sample in self.train_data])
        self.feature_scaler = StandardScaler()
        self.feature_scaler.fit(all_train_features)

        print("æ•°æ®å‡†å¤‡å®Œæˆ!")

    def _generate_training_data(self, positions, dt, vehicle_type):
        """ç”Ÿæˆè®­ç»ƒæ•°æ®"""
        training_samples = []
        window_size = 20

        vehicle_map = {"micro_quad": 0, "medium_large_quad": 1, "fixed_wing": 2, "heavy_multirotor": 3}
        vehicle_label = vehicle_map.get(vehicle_type, 1)

        for i in range(window_size, len(positions) - 1):
            pos_window = positions[i - window_size:i]
            vel_window = np.diff(pos_window, axis=0) / dt

            features = self._extract_sequence_features(pos_window, vel_window, dt)
            target_pos = positions[i + 1]

            training_samples.append({
                'features': features,
                'target_pos': target_pos,
                'current_pos': positions[i],
                'vehicle_type': vehicle_type,
                'vehicle_label': vehicle_label,
                'dt': dt
            })

        return training_samples

    def _extract_sequence_features(self, pos_window, vel_window, dt):
        """ä¿æŒåŸæœ‰çš„ç‰¹å¾æå–é€»è¾‘"""
        pos_mean = np.mean(pos_window, axis=0)
        pos_std = np.std(pos_window, axis=0)

        vel_mean = np.mean(vel_window, axis=0) if len(vel_window) > 0 else np.zeros(3)
        vel_std = np.std(vel_window, axis=0) if len(vel_window) > 0 else np.zeros(3)
        vel_norm_mean = np.mean(np.linalg.norm(vel_window, axis=1)) if len(vel_window) > 0 else 0.0

        traj_length = np.sum(np.linalg.norm(np.diff(pos_window, axis=0), axis=1))
        displacement = np.linalg.norm(pos_window[-1] - pos_window[0])

        features = np.concatenate([
            pos_mean, pos_std, vel_mean, vel_std,
            [vel_norm_mean, traj_length, displacement, dt]
        ])

        return features

    def evaluate_on_test_set(self, model):
        """æµ‹è¯•é›†è¯„ä¼° - Q/Rç¼©æ”¾ç‰ˆæœ¬"""
        model.eval()

        qr_scales_collected = []
        confidence_collected = []
        vehicle_accuracy = []
        errors_collected = []
        success_count = 0
        failure_count = 0

        print("    ä½¿ç”¨Q/Rç¼©æ”¾è‡ªé€‚åº”é¢„æµ‹å™¨ (æ™ºèƒ½UKFåŸºç¡€Q/R + Transformerç¼©æ”¾)")
        predictor = QRScalingAdaptivePredictor(
            dt=self.median_dt,
            max_prediction_steps=3
        )

        with torch.no_grad():
            for i, sample in enumerate(self.test_data):
                try:
                    features = torch.tensor(
                        self.feature_scaler.transform([sample['features']]),
                        dtype=torch.float32, device=self.device
                    )

                    # Q/Rç¼©æ”¾Transformerè¾“å‡º
                    qr_scales, confidence, vehicle_probs, vehicle_logits = model(features)

                    # æ”¶é›†ç»Ÿè®¡
                    qr_scales_collected.append(qr_scales.detach().cpu().numpy().flatten())
                    confidence_collected.append(float(confidence))

                    # è½½å…·ç±»å‹å‡†ç¡®ç‡
                    predicted_vehicle = torch.argmax(vehicle_probs).item()
                    true_vehicle = sample['vehicle_label']
                    vehicle_accuracy.append(1 if predicted_vehicle == true_vehicle else 0)

                    # Q/Rç¼©æ”¾è‡ªé€‚åº”é¢„æµ‹
                    try:
                        _, error = predictor.safe_predict(
                            (qr_scales, confidence, vehicle_probs, vehicle_logits),
                            sample['current_pos'],
                            sample['target_pos'],
                            verbose=(i < 2)
                        )

                        if error != float('inf'):
                            errors_collected.append(error)
                            success_count += 1
                        else:
                            failure_count += 1

                    except Exception as e:
                        failure_count += 1
                        if i < 2:
                            print(f"    é¢„æµ‹å¼‚å¸¸(æ ·æœ¬{i}): {str(e)[:50]}")

                except Exception as e:
                    if i < 2:
                        print(f"    è¯„ä¼°å¤±è´¥: {e}")
                    continue

        # ç»Ÿè®¡åˆ†æ
        success_rate = success_count / max(success_count + failure_count, 1)
        print(f"    [Q/Rç¼©æ”¾è‡ªé€‚åº”] æˆåŠŸç‡: {success_rate:.1%} ({success_count}/{success_count + failure_count})")

        if len(errors_collected) > 0:
            error_mean = np.mean(errors_collected)
            error_std = np.std(errors_collected)
            print(f"    [è¯¯å·®] å‡å€¼: {error_mean:.6f} Â± {error_std:.6f}")
        else:
            error_mean = float('inf')
            print(f"    âœ— æ‰€æœ‰é¢„æµ‹éƒ½å¤±è´¥")

        if len(confidence_collected) > 0:
            avg_confidence = np.mean(confidence_collected)
            print(f"    [ç½®ä¿¡åº¦] å¹³å‡: {avg_confidence:.4f}")

        if len(vehicle_accuracy) > 0:
            vehicle_acc = np.mean(vehicle_accuracy)
            print(f"    [è½½å…·è¯†åˆ«] å‡†ç¡®ç‡: {vehicle_acc:.1%}")

        if len(qr_scales_collected) > 0:
            avg_qr = np.mean(qr_scales_collected, axis=0)
            std_qr = np.std(qr_scales_collected, axis=0)
            print(f"    [Q/Rç¼©æ”¾] Q={avg_qr[0]:.3f}Â±{std_qr[0]:.3f}, R={avg_qr[1]:.3f}Â±{std_qr[1]:.3f}")

        # æ˜¾ç¤ºQ/Rç¼©æ”¾ç­–ç•¥ç»Ÿè®¡
        usage_stats = predictor.get_usage_stats()
        print(f"    [Q/Rç¼©æ”¾ç­–ç•¥] NNç¼©æ”¾: {usage_stats['nn_qr_scaling']:.1f}%, "
              f"æ··åˆç¼©æ”¾: {usage_stats['hybrid_qr_scaling']:.1f}%, "
              f"é»˜è®¤ç¼©æ”¾: {usage_stats['default_qr_scaling']:.1f}%")

        return error_mean

    def train_model(self, train_params):
        """è®­ç»ƒQ/Rç¼©æ”¾æ¨¡å‹"""
        seed = train_params.get('seed', 42)
        epochs = train_params.get('epochs', 50)
        batch_size = train_params.get('batch_size', 16)
        lr = train_params.get('lr', 3e-5)
        d_model = train_params.get('d_model', 128)
        nlayers = train_params.get('nlayers', 2)
        nhead = train_params.get('nhead', 4)
        dropout = train_params.get('dropout', 0.1)
        weight_decay = train_params.get('weight_decay', 0.0001)
        patience = train_params.get('patience', 15)
        reservoir_size = train_params.get('reservoir_size', 32)

        torch.manual_seed(seed)
        np.random.seed(seed)

        print(f"\nå¼€å§‹Q/Rç¼©æ”¾ç‰ˆè®­ç»ƒ (ç§å­: {seed})")

        # åˆ›å»ºQ/Rç¼©æ”¾æ¨¡å‹
        input_dim = len(self.train_data[0]['features'])
        model = QRScalingTransformerNN(
            input_dim=input_dim,
            d_model=d_model,
            nlayers=nlayers,
            nhead=nhead,
            dropout=dropout,
            reservoir_size=reservoir_size
        ).to(self.device)

        print(f"Q/Rç¼©æ”¾Transformerå‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        print(f"æ¶æ„: d_model={d_model}, nlayers={nlayers}, nhead={nhead}, reservoir_size={reservoir_size}")

        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=8, factor=0.5, min_lr=1e-6)

        best_error = float('inf')
        best_model_state = None
        patience_counter = 0

        # åˆ›å»ºè®­ç»ƒç”¨é¢„æµ‹å™¨
        train_predictor = QRScalingAdaptivePredictor(dt=self.median_dt, max_prediction_steps=3)

        for epoch in range(epochs):
            model.train()
            epoch_errors = []

            indices = np.random.permutation(len(self.train_data))

            for i in range(0, len(indices), batch_size):
                batch_indices = indices[i:i + batch_size]

                optimizer.zero_grad()
                batch_error = 0.0
                valid_count = 0

                for idx in batch_indices:
                    sample = self.train_data[idx]
                    features = torch.tensor(
                        self.feature_scaler.transform([sample['features']]),
                        dtype=torch.float32, device=self.device
                    )

                    # Q/Rç¼©æ”¾å‰å‘ä¼ æ’­
                    qr_scales, confidence, vehicle_probs, vehicle_logits = model(features)

                    # åŸºäºQ/Rç¼©æ”¾é¢„æµ‹çš„æŸå¤±å‡½æ•°
                    try:
                        _, error = train_predictor.safe_predict(
                            (qr_scales, confidence, vehicle_probs, vehicle_logits),
                            sample['current_pos'],
                            sample['target_pos'],
                            verbose=False
                        )

                        if error != float('inf'):
                            # ä¸»æŸå¤±ï¼šé¢„æµ‹è¯¯å·®
                            main_loss = error

                            # è¾…åŠ©æŸå¤±ï¼šè½½å…·ç±»å‹åˆ†ç±»
                            vehicle_label = torch.tensor([sample['vehicle_label']],
                                                         dtype=torch.long, device=self.device)
                            vehicle_loss = F.cross_entropy(vehicle_logits, vehicle_label)

                            # æ­£åˆ™åŒ–ï¼šQ/Rç¼©æ”¾å› å­åˆç†æ€§
                            qr_reg = torch.mean((qr_scales - 1.0) ** 2)  # é¼“åŠ±æ¥è¿‘1.0

                            # æ€»æŸå¤±
                            total_loss = main_loss + 0.1 * vehicle_loss + 0.01 * qr_reg

                            batch_error += total_loss
                            valid_count += 1

                    except Exception:
                        continue

                if valid_count > 0:
                    batch_error = batch_error / valid_count

                    # åå‘ä¼ æ’­
                    batch_error.backward()
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    optimizer.step()

                    epoch_errors.append(batch_error.item())

            # è®¡ç®—å¹³å‡æŸå¤±
            if epoch_errors:
                avg_error = np.mean(epoch_errors)

                # æµ‹è¯•é›†è¯„ä¼°
                test_error = self.evaluate_on_test_set(model)

                scheduler.step(test_error)

                # æ—©åœæ£€æŸ¥
                if test_error < best_error:
                    best_error = test_error
                    best_model_state = copy.deepcopy(model.state_dict())
                    patience_counter = 0
                else:
                    patience_counter += 1

                print(f"Epoch {epoch + 1:2d}/{epochs}: "
                      f"Train={avg_error:.6f}, Test={test_error:.6f}, "
                      f"LR={optimizer.param_groups[0]['lr']:.1e}")

                if patience_counter >= patience:
                    print(f"æ—©åœè§¦å‘ (patience={patience})")
                    break

        # æ¢å¤æœ€ä½³æ¨¡å‹
        if best_model_state is not None:
            model.load_state_dict(best_model_state)

        return {
            'model': model,
            'best_error': best_error,
            'seed': seed,
            'mode': 'qr_scaling_hybrid_with_smart_ukf',
            'architecture': {
                'd_model': d_model,
                'nlayers': nlayers,
                'nhead': nhead,
                'dropout': dropout,
                'reservoir_size': reservoir_size
            }
        }


def main():
    parser = argparse.ArgumentParser(description='Q/Rç¼©æ”¾ç‰ˆæ··åˆç³»ç»Ÿï¼šæ™ºèƒ½UKFåŸºç¡€Q/R + Transformerç¼©æ”¾')
    parser.add_argument('--data_path', type=str, required=True, help='è®­ç»ƒæ•°æ®è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./qr_scaling_models', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--device', type=str, default='cpu', help='è®¾å¤‡')

    args = parser.parse_args()

    os.makedirs(args.output_dir, exist_ok=True)

    print("Q/Rç¼©æ”¾ç‰ˆæ··åˆç³»ç»Ÿ")
    print("=" * 60)
    print("æ ¸å¿ƒæ¶æ„:")
    print("âœ“ æ™ºèƒ½UKFï¼šæ¯30æ­¥æ ¹æ®è½½å…·ç±»å‹+é£è¡Œæ¨¡å¼è°ƒæ•´åŸºç¡€Q/R")
    print("âœ“ Transformerï¼šå®æ—¶é¢„æµ‹Q/Rç¼©æ”¾å› å­[0.1-3.0, 0.5-2.0]")
    print("âœ“ æœ€ç»ˆQ/R = åŸºç¡€Q/R Ã— ç¼©æ”¾å› å­")
    print("âœ“ Reservoirè®°å¿†å¢å¼ºæ—¶åºå­¦ä¹ ")
    print("âœ“ ç½®ä¿¡åº¦è‡ªé€‚åº”èåˆç­–ç•¥")
    print("âœ“ ç§»é™¤è®­ç»ƒæœ€å¤§å¸§æ•°é™åˆ¶")
    print(f"æ•°æ®: {args.data_path}")

    try:
        trainer = QRScalingHybridTrainer(
            args.data_path,
            args.device
        )

        seeds = [42, 123, 456, 789, 1024]
        results = []

        for seed in seeds:
            train_params = {
                'seed': seed,
                'epochs': 50,
                'batch_size': 16,
                'lr': 3e-5,
                'd_model': 128,
                'nlayers': 2,
                'nhead': 4,
                'dropout': 0.1,
                'weight_decay': 0.0001,
                'patience': 15,
                'reservoir_size': 32
            }

            print(f"\n{'=' * 60}")
            print(f"è®­ç»ƒç§å­ {seed} (Q/Rç¼©æ”¾ç‰ˆï¼šæ™ºèƒ½UKF + Transformer + Reservoir + ç½®ä¿¡åº¦)")
            print(f"{'=' * 60}")

            result = trainer.train_model(train_params)
            results.append(result)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            model_path = os.path.join(args.output_dir, f'qr_scaling_seed_{seed}_{timestamp}.pth')

            torch.save({
                'model_state_dict': result['model'].state_dict(),
                'feature_scaler': trainer.feature_scaler,
                'train_params': train_params,
                'result': result,
                'method': 'qr_scaling_hybrid_with_smart_ukf',
                'model_type': 'QRScalingTransformerNN',
                'dt': trainer.median_dt,
                'version': '8.0_qr_scaling_unlimited_data'
            }, model_path)

            print(f"\nâœ“ ç§å­{seed}è®­ç»ƒå®Œæˆ:")
            print(f"  è¯¯å·®: {result['best_error']:.6f}")
            print(f"  æ¨¡å¼: {result['mode']}")
            print(f"  ä¿å­˜è‡³: {model_path}")

        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        best_result = min(results, key=lambda x: x['best_error'])
        print(f"\n{'=' * 60}")
        print(f"Q/Rç¼©æ”¾ç‰ˆè®­ç»ƒå®Œæˆæ€»ç»“")
        print(f"{'=' * 60}")

        for result in results:
            status = "ğŸ† BEST" if result == best_result else "   "
            print(f"{status} ç§å­{result['seed']}: è¯¯å·®={result['best_error']:.6f}")

        best_model_path = os.path.join(args.output_dir, f'BEST_qr_scaling.pth')
        torch.save({
            'model_state_dict': best_result['model'].state_dict(),
            'feature_scaler': trainer.feature_scaler,
            'train_params': train_params,
            'result': best_result,
            'method': 'qr_scaling_hybrid_with_smart_ukf',
            'model_type': 'QRScalingTransformerNN',
            'dt': trainer.median_dt,
            'all_results': results,
            'version': '8.0_qr_scaling_unlimited_data'
        }, best_model_path)

        print(f"\nâœ“ æœ€ä½³Q/Rç¼©æ”¾æ¨¡å‹ä¿å­˜è‡³: {best_model_path}")
        print(f"âœ“ æœ€ä½³æ€§èƒ½: è¯¯å·®={best_result['best_error']:.6f}")

        print(f"\nQ/Rç¼©æ”¾ç­–ç•¥æ•ˆæœ:")
        print("1. æ™ºèƒ½UKFæä¾›åŸºç¡€Q/RçŸ©é˜µï¼ˆè½½å…·ç±»å‹+é£è¡Œæ¨¡å¼é€‚é…ï¼‰")
        print("2. Transformerå­¦ä¹ å®æ—¶ç¼©æ”¾å› å­ï¼ˆè½¨è¿¹ç‰¹å¾é©±åŠ¨ï¼‰")
        print("3. åˆ†å±‚ä¼˜åŒ–ï¼šç²—è°ƒ(æ™ºèƒ½UKF) + ç²¾è°ƒ(Transformer)")
        print("4. Reservoirè®°å¿†ï¼šå¢å¼ºå¤æ‚è½¨è¿¹æ¨¡å¼å­¦ä¹ ")
        print("5. ç½®ä¿¡åº¦èåˆï¼šè‡ªé€‚åº”é€‰æ‹©æœ€ä¼˜ç¼©æ”¾ç­–ç•¥")
        print("6. æ— æ•°æ®é™åˆ¶ï¼šä½¿ç”¨å®Œæ•´è½¨è¿¹æ•°æ®è¿›è¡Œè®­ç»ƒ")

    except Exception as e:
        print(f"è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()